{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac31a9a-850a-4e45-a05e-c295c97e2e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D-InfoTech\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,344</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │           \u001b[38;5;34m9,344\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_12 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m263,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_13 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m164,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">436,993</span> (1.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m436,993\u001b[0m (1.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">436,993</span> (1.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m436,993\u001b[0m (1.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 7463.6064 - mae: 74.9420 - val_loss: 6777.9517 - val_mae: 71.2600\n",
      "Epoch 2/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 5918.5820 - mae: 65.3532 - val_loss: 6327.2603 - val_mae: 68.5654\n",
      "Epoch 3/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 5541.4087 - mae: 63.0430 - val_loss: 5961.5991 - val_mae: 66.3716\n",
      "Epoch 4/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 5293.0210 - mae: 61.5527 - val_loss: 5633.7065 - val_mae: 64.3949\n",
      "Epoch 5/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 4936.1074 - mae: 59.2550 - val_loss: 5330.9233 - val_mae: 62.5575\n",
      "Epoch 6/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 4670.5449 - mae: 57.6252 - val_loss: 5037.9668 - val_mae: 60.5644\n",
      "Epoch 7/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 4316.1597 - mae: 54.6265 - val_loss: 4731.4370 - val_mae: 57.6572\n",
      "Epoch 8/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 4058.1985 - mae: 51.9365 - val_loss: 4452.9453 - val_mae: 55.3094\n",
      "Epoch 9/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3887.8970 - mae: 50.4704 - val_loss: 4195.7612 - val_mae: 53.3886\n",
      "Epoch 10/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3600.5657 - mae: 48.0826 - val_loss: 3952.0037 - val_mae: 51.4441\n",
      "Epoch 11/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 3389.4316 - mae: 46.2176 - val_loss: 3720.5464 - val_mae: 49.7100\n",
      "Epoch 12/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3203.4053 - mae: 44.7605 - val_loss: 3502.0139 - val_mae: 48.0068\n",
      "Epoch 13/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 2981.0679 - mae: 42.8122 - val_loss: 3296.6467 - val_mae: 46.5260\n",
      "Epoch 14/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2828.0371 - mae: 41.7530 - val_loss: 3105.0720 - val_mae: 44.9867\n",
      "Epoch 15/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2685.2229 - mae: 40.3573 - val_loss: 2907.1086 - val_mae: 43.1979\n",
      "Epoch 16/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2426.8484 - mae: 37.8757 - val_loss: 2726.9551 - val_mae: 41.6920\n",
      "Epoch 17/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 2350.3608 - mae: 37.3396 - val_loss: 2557.2749 - val_mae: 40.3012\n",
      "Epoch 18/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 2166.0513 - mae: 35.6547 - val_loss: 2400.9294 - val_mae: 38.9412\n",
      "Epoch 19/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 1971.4408 - mae: 33.5860 - val_loss: 2241.9863 - val_mae: 37.5033\n",
      "Epoch 20/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 1886.0100 - mae: 32.9217 - val_loss: 2098.5369 - val_mae: 36.2114\n",
      "Epoch 21/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 1733.0480 - mae: 31.3468 - val_loss: 1955.5048 - val_mae: 34.8725\n",
      "Epoch 22/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 1617.8790 - mae: 30.1702 - val_loss: 1833.0515 - val_mae: 33.7869\n",
      "Epoch 23/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 1544.1399 - mae: 29.6099 - val_loss: 1705.5618 - val_mae: 32.4402\n",
      "Epoch 24/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 1407.1014 - mae: 28.0043 - val_loss: 1590.2043 - val_mae: 31.2867\n",
      "Epoch 25/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 1318.1094 - mae: 27.0644 - val_loss: 1475.7716 - val_mae: 30.1490\n",
      "Epoch 26/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 1222.3572 - mae: 25.9962 - val_loss: 1396.1896 - val_mae: 29.7871\n",
      "Epoch 27/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 1147.3571 - mae: 25.3446 - val_loss: 1277.7374 - val_mae: 28.1010\n",
      "Epoch 28/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 1050.0511 - mae: 24.0776 - val_loss: 1188.1575 - val_mae: 27.0639\n",
      "Epoch 29/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 977.1406 - mae: 23.1617 - val_loss: 1103.7867 - val_mae: 26.3216\n",
      "Epoch 30/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 894.6092 - mae: 22.2143 - val_loss: 1023.3790 - val_mae: 25.3294\n",
      "Epoch 31/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 815.3292 - mae: 21.0499 - val_loss: 941.5402 - val_mae: 24.3855\n",
      "Epoch 32/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 751.2314 - mae: 20.2593 - val_loss: 870.3652 - val_mae: 23.4218\n",
      "Epoch 33/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 693.4534 - mae: 19.4462 - val_loss: 804.2530 - val_mae: 22.6701\n",
      "Epoch 34/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 638.6613 - mae: 18.6105 - val_loss: 741.9057 - val_mae: 21.7200\n",
      "Epoch 35/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 579.9326 - mae: 17.8310 - val_loss: 684.2363 - val_mae: 20.9814\n",
      "Epoch 36/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 538.2754 - mae: 17.2114 - val_loss: 638.7423 - val_mae: 20.3987\n",
      "Epoch 37/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 499.0462 - mae: 16.7522 - val_loss: 606.0052 - val_mae: 19.9179\n",
      "Epoch 38/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 454.2815 - mae: 15.9525 - val_loss: 558.4790 - val_mae: 19.2088\n",
      "Epoch 39/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 412.8493 - mae: 15.1632 - val_loss: 537.4384 - val_mae: 19.0409\n",
      "Epoch 40/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 392.5644 - mae: 14.9418 - val_loss: 471.8762 - val_mae: 17.7384\n",
      "Epoch 41/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 349.5429 - mae: 14.0876 - val_loss: 453.5144 - val_mae: 17.4528\n",
      "Epoch 42/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 317.5023 - mae: 13.4006 - val_loss: 432.3539 - val_mae: 17.2142\n",
      "Epoch 43/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 302.9760 - mae: 13.2500 - val_loss: 386.5967 - val_mae: 16.2011\n",
      "Epoch 44/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 264.1417 - mae: 12.3176 - val_loss: 408.2709 - val_mae: 16.3390\n",
      "Epoch 45/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 244.8673 - mae: 11.8078 - val_loss: 361.0891 - val_mae: 15.4945\n",
      "Epoch 46/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 212.7114 - mae: 10.9927 - val_loss: 334.5114 - val_mae: 14.9383\n",
      "Epoch 47/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 200.7386 - mae: 10.6712 - val_loss: 334.0774 - val_mae: 14.7389\n",
      "Epoch 48/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 190.0683 - mae: 10.4023 - val_loss: 315.2399 - val_mae: 14.2691\n",
      "Epoch 49/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 177.2898 - mae: 10.0931 - val_loss: 301.1512 - val_mae: 13.9773\n",
      "Epoch 50/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 159.8952 - mae: 9.5924 - val_loss: 297.9541 - val_mae: 13.8452\n",
      "Epoch 51/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 147.2026 - mae: 9.1639 - val_loss: 297.5511 - val_mae: 13.5849\n",
      "Epoch 52/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 135.9154 - mae: 8.7229 - val_loss: 276.1260 - val_mae: 13.1685\n",
      "Epoch 53/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 131.5035 - mae: 8.5267 - val_loss: 296.0916 - val_mae: 13.2904\n",
      "Epoch 54/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 122.0066 - mae: 8.2128 - val_loss: 299.1509 - val_mae: 13.1556\n",
      "Epoch 55/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 130.3521 - mae: 8.5053 - val_loss: 257.7029 - val_mae: 12.4022\n",
      "Epoch 56/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 112.6701 - mae: 7.7848 - val_loss: 259.7882 - val_mae: 12.3476\n",
      "Epoch 57/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 111.2084 - mae: 7.7205 - val_loss: 260.6444 - val_mae: 12.2412\n",
      "Epoch 58/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 105.0702 - mae: 7.5196 - val_loss: 266.0133 - val_mae: 12.1905\n",
      "Epoch 59/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 98.8945 - mae: 7.2755 - val_loss: 284.4590 - val_mae: 12.6711\n",
      "Epoch 60/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 94.3064 - mae: 7.0511 - val_loss: 256.2881 - val_mae: 11.7615\n",
      "Epoch 61/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 91.9554 - mae: 6.8989 - val_loss: 264.0151 - val_mae: 11.8414\n",
      "Epoch 62/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 88.9934 - mae: 6.8026 - val_loss: 272.0711 - val_mae: 11.8836\n",
      "Epoch 63/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 87.8063 - mae: 6.7078 - val_loss: 289.1575 - val_mae: 12.4972\n",
      "Epoch 64/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 81.2019 - mae: 6.5164 - val_loss: 258.1896 - val_mae: 11.6011\n",
      "Epoch 65/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 87.8454 - mae: 6.6755 - val_loss: 262.7811 - val_mae: 11.7629\n",
      "Epoch 66/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 80.2301 - mae: 6.4827 - val_loss: 288.4591 - val_mae: 12.1270\n",
      "Epoch 67/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 78.3993 - mae: 6.3211 - val_loss: 259.1365 - val_mae: 11.5275\n",
      "Epoch 68/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 75.1643 - mae: 6.2704 - val_loss: 275.7446 - val_mae: 11.7064\n",
      "Epoch 69/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 76.9029 - mae: 6.2971 - val_loss: 293.5349 - val_mae: 12.2230\n",
      "Epoch 70/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 72.6148 - mae: 6.1058 - val_loss: 276.9126 - val_mae: 12.0220\n",
      "Epoch 71/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 70.7803 - mae: 6.1067 - val_loss: 261.9926 - val_mae: 11.4142\n",
      "Epoch 72/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 64.4079 - mae: 5.8149 - val_loss: 275.7305 - val_mae: 11.9301\n",
      "Epoch 73/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - loss: 72.4517 - mae: 6.1642 - val_loss: 281.4177 - val_mae: 12.0051\n",
      "Epoch 74/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 65.4649 - mae: 5.8321 - val_loss: 259.8918 - val_mae: 11.4477\n",
      "Epoch 75/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 64.7638 - mae: 5.8250 - val_loss: 292.9663 - val_mae: 11.7005\n",
      "Epoch 76/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 62.1064 - mae: 5.7379 - val_loss: 296.1683 - val_mae: 12.4483\n",
      "Epoch 77/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - loss: 61.4962 - mae: 5.7036 - val_loss: 268.8140 - val_mae: 11.4819\n",
      "Epoch 78/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 61.1752 - mae: 5.6834 - val_loss: 264.9250 - val_mae: 11.5110\n",
      "Epoch 79/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 58.1424 - mae: 5.5775 - val_loss: 277.5125 - val_mae: 11.9386\n",
      "Epoch 80/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 59.5609 - mae: 5.5773 - val_loss: 274.5644 - val_mae: 11.5926\n",
      "Epoch 81/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 60.0491 - mae: 5.6045 - val_loss: 271.7269 - val_mae: 11.6460\n",
      "Epoch 82/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 58.4472 - mae: 5.5659 - val_loss: 301.5903 - val_mae: 12.5493\n",
      "Epoch 83/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 57.0374 - mae: 5.5083 - val_loss: 284.7261 - val_mae: 11.6111\n",
      "Epoch 84/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 54.9028 - mae: 5.4689 - val_loss: 275.3870 - val_mae: 11.6684\n",
      "Epoch 85/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 53.0823 - mae: 5.3039 - val_loss: 277.2129 - val_mae: 11.6422\n",
      "Epoch 86/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 55.5509 - mae: 5.4440 - val_loss: 281.6492 - val_mae: 12.2737\n",
      "Epoch 87/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 54.1169 - mae: 5.4275 - val_loss: 288.5273 - val_mae: 11.8638\n",
      "Epoch 88/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 51.1291 - mae: 5.2432 - val_loss: 278.6642 - val_mae: 11.4637\n",
      "Epoch 89/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 49.8568 - mae: 5.1736 - val_loss: 277.4301 - val_mae: 11.6302\n",
      "Epoch 90/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 49.6002 - mae: 5.2252 - val_loss: 272.9438 - val_mae: 11.4916\n",
      "Epoch 91/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 51.5947 - mae: 5.2849 - val_loss: 292.5488 - val_mae: 12.1071\n",
      "Epoch 92/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 48.5029 - mae: 5.1643 - val_loss: 291.5312 - val_mae: 11.4526\n",
      "Epoch 93/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 48.7683 - mae: 5.1590 - val_loss: 288.5020 - val_mae: 11.7100\n",
      "Epoch 94/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 49.3291 - mae: 5.1918 - val_loss: 286.4796 - val_mae: 12.1091\n",
      "Epoch 95/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 47.7129 - mae: 5.0957 - val_loss: 274.6308 - val_mae: 11.2459\n",
      "Epoch 96/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 46.5389 - mae: 5.0546 - val_loss: 283.9251 - val_mae: 12.0687\n",
      "Epoch 97/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 47.0315 - mae: 5.1008 - val_loss: 297.7476 - val_mae: 12.2003\n",
      "Epoch 98/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 45.1926 - mae: 4.9765 - val_loss: 290.2608 - val_mae: 11.5237\n",
      "Epoch 99/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 47.4778 - mae: 5.1114 - val_loss: 309.2710 - val_mae: 12.5718\n",
      "Epoch 100/100\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 45.8090 - mae: 5.0307 - val_loss: 287.9921 - val_mae: 11.6416\n",
      "Training Time: 863.68 seconds\n",
      "X_test_final shape before predict: (100, 30, 24)\n",
      "Model input shape: (None, 30, 24)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step\n",
      "y_pred shape: (100,)\n",
      "CNN-BiLSTM Hybrid Model: RMSE=325.49, MAE=13.33, R²=0.81, Accuracy=79.43%, Score=814.09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Bidirectional, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "# ---------------------- Load Data ----------------------\n",
    "column_names = ['engine_id', 'cycle', 'op_setting_1', 'op_setting_2', 'op_setting_3'] + [f'sensor_{i}' for i in range(1, 24)]\n",
    "train_df = pd.read_csv(\"train_FD001.txt\", sep=\"\\s+\", header=None, names=column_names)\n",
    "test_df = pd.read_csv(\"test_FD001.txt\", sep=\"\\s+\", header=None, names=column_names)\n",
    "rul_df = pd.read_csv(\"RUL_FD001.txt\", header=None, names=[\"true_RUL\"])\n",
    "rul_df[\"engine_id\"] = rul_df.index + 1\n",
    "\n",
    "# Add RUL to train set\n",
    "max_cycle = train_df.groupby('engine_id')['cycle'].max().reset_index()\n",
    "max_cycle.columns = ['engine_id', 'max_cycle']\n",
    "train_df = train_df.merge(max_cycle, on='engine_id')\n",
    "train_df['RUL'] = train_df['max_cycle'] - train_df['cycle']\n",
    "train_df.drop('max_cycle', axis=1, inplace=True)\n",
    "\n",
    "# Add RUL to test set\n",
    "test_max_cycle = test_df.groupby('engine_id')['cycle'].max().reset_index()\n",
    "test_max_cycle.columns = ['engine_id', 'max_cycle']\n",
    "test_df = test_df.merge(test_max_cycle, on='engine_id')\n",
    "test_df['RUL'] = test_df['max_cycle'] - test_df['cycle']\n",
    "test_df.drop('max_cycle', axis=1, inplace=True)\n",
    "\n",
    "# Clip RUL (optional but common)\n",
    "rul_cap = 130\n",
    "train_df['RUL'] = train_df['RUL'].clip(upper=rul_cap)\n",
    "test_df['RUL'] = test_df['RUL'].clip(upper=rul_cap)\n",
    "\n",
    "# ---------------------- Preprocess ----------------------\n",
    "features = train_df.columns.difference(['engine_id', 'cycle', 'RUL', 'sensor_22', 'sensor_23'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_df[features] = scaler.fit_transform(train_df[features])\n",
    "test_df[features] = scaler.transform(test_df[features])\n",
    "\n",
    "# ---------------------- Sequence Creator ----------------------\n",
    "sequence_length = 30\n",
    "\n",
    "def create_sequences(df, sequence_length, features):\n",
    "    sequences, labels = [], []\n",
    "    for engine_id in df['engine_id'].unique():\n",
    "        engine_data = df[df['engine_id'] == engine_id]\n",
    "        for i in range(len(engine_data) - sequence_length):\n",
    "            seq = engine_data[features].iloc[i:i+sequence_length].values\n",
    "            label = engine_data['RUL'].iloc[i + sequence_length]\n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(train_df, sequence_length, features)\n",
    "num_features = X_train_seq.shape[2]\n",
    "\n",
    "# ---------------------- Model ----------------------\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(sequence_length, num_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# ---------------------- Training ----------------------\n",
    "start_time = time.time()\n",
    "model.fit(X_train_seq, y_train_seq, validation_split=0.25, epochs=100, batch_size=64)\n",
    "print(f\"Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# ---------------------- Test Evaluation ----------------------\n",
    "# Only take the last sequence per engine\n",
    "test_sequences = []\n",
    "valid_engine_ids = []\n",
    "\n",
    "for engine_id in test_df[\"engine_id\"].unique():\n",
    "    engine_data = test_df[test_df[\"engine_id\"] == engine_id]\n",
    "    if len(engine_data) >= sequence_length:\n",
    "        last_seq = engine_data[features].iloc[-sequence_length:].values\n",
    "        test_sequences.append(last_seq)\n",
    "        valid_engine_ids.append(engine_id)\n",
    "\n",
    "X_test_final = np.array(test_sequences)\n",
    "print(\"X_test_final shape before predict:\", X_test_final.shape)\n",
    "print(\"Model input shape:\", model.input_shape)\n",
    "y_pred = model.predict(X_test_final).flatten()\n",
    "print(\"y_pred shape:\", y_pred.shape)  # Should be (100,)\n",
    "y_true = rul_df[rul_df[\"engine_id\"].isin(valid_engine_ids)][\"true_RUL\"].values\n",
    "\n",
    "\n",
    "# ---------------------- Evaluation ----------------------\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    rmse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    accuracy = 100 - mape\n",
    "    h = y_pred - y_true\n",
    "    score = np.sum(np.where(h < 0, np.exp(-h / 13) - 1, np.exp(h / 10) - 1))\n",
    "    print(f\"{name}: RMSE={rmse:.2f}, MAE={mae:.2f}, R²={r2:.2f}, Accuracy={accuracy:.2f}%, Score={score:.2f}\")\n",
    "\n",
    "evaluate_model(\"CNN-BiLSTM Hybrid Model\", y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8126d1a-e0df-4fd7-a9a2-306f4878c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119.398476  124.31119    43.447796  125.05897    86.02975   108.214355\n",
      " 120.843185  120.520874  128.01208    92.74121    89.56775   105.34804\n",
      "  82.15187   100.80336    96.701805   99.983215   56.065754   31.997206\n",
      "  88.941376   14.772558   89.53344   129.12611   129.11362    18.747961\n",
      " 109.85289   105.32471   103.99496    89.19165    86.168015  100.08197\n",
      "   9.0746975  55.34666   128.24188     5.8481665  17.22873    22.01872\n",
      "  37.78433    65.62877   128.15746    33.390106   30.277021   10.955322\n",
      "  84.25946   127.78528    98.32408    31.82313   124.60323   105.86696\n",
      "  15.586316  126.94974    91.82101    30.255625   30.506048  128.47101\n",
      " 124.80773    16.525417   96.35958    54.18444   115.92589   101.50987\n",
      "  20.648531   56.09933    94.16754    29.026627  128.67621    15.696024\n",
      " 128.3964     11.418528  128.83833    92.041245  121.03865    80.035385\n",
      "  97.865746   91.77104   111.15451     7.412954   34.312508  129.42343\n",
      "  89.36007    98.41931     6.796429    9.791659  128.9452     90.0833\n",
      " 129.19003   124.146805  103.56456   104.48137   128.66902    33.84222\n",
      "  21.38959    24.9807     46.06651    88.12188   129.0018    126.65945\n",
      "  83.79703    63.469337  128.69682    16.476357 ]\n"
     ]
    }
   ],
   "source": [
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816a3ae-130c-43f5-bd6a-4102939d46c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (TF)",
   "language": "python",
   "name": "tf311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
